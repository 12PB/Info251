{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_rWlx66e6rb"
   },
   "source": [
    "# Lab 13 - Pipelines and Imbalanced Data\n",
    "- **Author:** Satej Soman, Suraj R. Nair\n",
    "- **Date:** April 16, 2025\n",
    "- **Course:** INFO 251: Applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_rhM6Q3fCwQ"
   },
   "source": [
    "## Learning Goals:\n",
    "\n",
    "- Building pipelines using sklearn\n",
    "- Implement methods to handle imbalanced data\n",
    "- Introduction to [Imbalanced-learn package](https://imbalanced-learn.org/stable/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oid2EbV4fhtj"
   },
   "source": [
    "Today, we'll be working with an extract of US Census data (1994). Our goal is to predict whether individuals make over 50K USD, or not (Kohavi, 1996).  \n",
    "\n",
    "[Dataset documentation](https://www.openml.org/search?type=data&sort=runs&id=179&status=active)\n",
    "\n",
    "Reference: adapted from [this](https://imbalanced-learn.org/stable/auto_examples/applications/plot_impact_imbalanced_classes.html) imblearn tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "awCSQGSBP5C_"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "df, y = fetch_openml(\"adult\", version=2, as_frame=True, return_X_y=True)\n",
    "df = df.drop(columns=[\"fnlwgt\", \"education-num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yG7U7a_9Qxn4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "<=50K    37155\n",
       ">50K     11687\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_count = y.value_counts()\n",
    "classes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WSpR4fH1QC0r"
   },
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMgx2t60ghr7"
   },
   "source": [
    "Let's make the classes further imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ck4Qp8fmQ3cK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    37155\n",
       "1     3715\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 10 ## Feel free to tinker with this\n",
    "df_res, y_res = make_imbalance(\n",
    "    df,\n",
    "    y,\n",
    "    sampling_strategy={classes_count.idxmin(): classes_count.max() // ratio},\n",
    ")\n",
    "y_res_clean = (y_res == \">50K\")*1\n",
    "y_res_clean.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Tf31xEogzG2"
   },
   "source": [
    "## A. Dummy Classifier\n",
    "\n",
    "The [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) in sklearn makes predictions which ignore the input features. This serves a useful (and naive) baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sIZZyxkcQ8V8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\") ## Predicts the most frequent class\n",
    "scoring = [\"accuracy\"]\n",
    "dummy_cv_result = cross_validate(dummy_clf, df_res, y_res, scoring=scoring)\n",
    "print(f\"Dummy Accuracy: {dummy_cv_result['test_accuracy'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slKHzlr1hbu1"
   },
   "source": [
    "Let's create a some variables to store the results from this, and all following experiments.\n",
    "\n",
    "Before we continue, intuition check -- what are the precision and recall for this dummy classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0-Ut-7feY8i9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy  Precision  Recall\n",
       "Dummy Classifier  0.909102   0.909091       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [\"Dummy Classifier\"]\n",
    "scores = {'Accuracy':[dummy_cv_result['test_accuracy'].mean()],\n",
    "          'Precision':[ratio/(ratio + 1)], ## FILL IN PRECISION\n",
    "          'Recall':[1]} ## FILL IN RECALL\n",
    "pd.DataFrame(scores, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artifically high statitics, just reflecting class imbalance > actual statistical accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2ryc7o-hxmd"
   },
   "source": [
    "## B. Logistic Regression\n",
    "\n",
    "Let's start with a linear model. Since we're going to repeat a lot of our pre-processing steps, we can build a pipeline to simplify things.\n",
    "\n",
    "The sklearn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) makes it easy to chain / link together several steps which can be cross-validated together while setting different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RIov_d5uYm9-"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Specify how to handle numeric variables\n",
    "num_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    ")\n",
    "\n",
    "#Specify how to handle categorical variables\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Send numeric columns to the numeric pipeline, and categorical columns to the categorical pipeline\n",
    "preprocessor_linear = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\"))\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Add in details of your model\n",
    "lr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))\n",
    "\n",
    "## 5 fold cross-validation\n",
    "lr_cv_result = cross_validate(lr_clf,\n",
    "                              df_res,\n",
    "                              y_res_clean,\n",
    "                              scoring=[\"accuracy\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wn9_CgtiZeGK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression (LR)</th>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.313594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision    Recall\n",
       "Dummy Classifier          0.909102   0.909091  1.000000\n",
       "Logistic regression (LR)  0.926866   0.727426  0.313594"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Store results in the dictionary from above\n",
    "index += [\"Logistic regression (LR)\"]\n",
    "\n",
    "scores[\"Accuracy\"].append(lr_cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(lr_cv_result[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(lr_cv_result[\"test_recall\"].mean())\n",
    "\n",
    "pd.DataFrame(scores, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S curve? Vanilla classifiers not useful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drHIsybfjAFH"
   },
   "source": [
    "## C. Logistic Regression with class weights\n",
    "\n",
    "Most of the models in `scikit-learn` have a parameter `class_weight`, which influences the computation of the loss/criterion -- applying different penalties to incorrect classification from the minority and majority class.\n",
    "\n",
    "`class_weight=\"balanced\"`: weight applied is inversely proportional to the class frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1Gsc7YBWacxW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression (LR)</th>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.313594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + class weights</th>\n",
       "      <td>0.798116</td>\n",
       "      <td>0.289704</td>\n",
       "      <td>0.840646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision    Recall\n",
       "Dummy Classifier          0.909102   0.909091  1.000000\n",
       "Logistic regression (LR)  0.926866   0.727426  0.313594\n",
       "LR + class weights        0.798116   0.289704  0.840646"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Update the pipeline parameters\n",
    "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\n",
    "\n",
    "#Cross-validation\n",
    "lr_cv_result_w = cross_validate(lr_clf, df_res, y_res_clean, scoring=[\"accuracy\", \"precision\", \"recall\"])\n",
    "\n",
    "\n",
    "# Save the scores\n",
    "index += [\"LR + class weights\"]\n",
    "scores[\"Accuracy\"].append(lr_cv_result_w[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(lr_cv_result_w[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(lr_cv_result_w[\"test_recall\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Custom Loss Functions\n",
    "\n",
    "In satellite imagery, for example, many of the potential inputs to do not have a useful label, but we may end up passing them to the model during training because of our sampling mechanism. We can create a custom loss function that ignores those labels. \n",
    "\n",
    "\n",
    "![satellite imagery with labeled classes](satellite_imagery.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic mse: tensor(1.2857) <class 'torch.Tensor'>\n",
      "custom mse: tensor(0.2000) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# example loss function:\n",
    "\n",
    "import torch\n",
    "\n",
    "def mse(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    loss = (y_pred - y_true)**2 \n",
    "    return loss.mean()\n",
    "\n",
    "def mse_custom(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    idx = (y_true == 0) | (y_true == 1)\n",
    "    return mse(y_pred[idx], y_true[idx])\n",
    "\n",
    "y_true = torch.Tensor([1, 0, 0, -1, 0, -1, 0])\n",
    "y_pred = torch.Tensor([1, 0, 1,  1, 0,  1, 0])\n",
    "\n",
    "original_loss = mse(y_pred, y_true)\n",
    "class_sensitive_loss = mse_custom(y_pred, y_true)\n",
    "print(\"basic mse:\", original_loss, type(original_loss))\n",
    "print(\"custom mse:\", class_sensitive_loss, type(class_sensitive_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can build your own loss functions. Custom loss functions are much easier to use in pytorch, keras etc instead of implementing in scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this custom function in a typical `PyTorch` training loop. \n",
    "\n",
    "```python\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    loss = mse_custom(labels, outputs)\n",
    "    loss.backward()\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "Any instance of `torch.Tensor` has a `backwards()` method (as does any implementation as of `torch.autograd.Function`). \n",
    "\n",
    "References: [1](https://discuss.pytorch.org/t/custom-loss-functions/29387), [2](https://discuss.pytorch.org/t/from-where-does-the-backward-method-come-in-custom-loss-functions/89416), [3](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _How is this related to the class weights we just discussed?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is another way of class weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E19wjz96jk-Y"
   },
   "source": [
    "## E. Resampling (Under/ Over)\n",
    "\n",
    "`imbalanced-learn` provides some samplers to handle resampling. Here, we'll example 1) Undersampling, and 2) SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jBdpHAoHcGcJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression (LR)</th>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.313594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + class weights</th>\n",
       "      <td>0.798116</td>\n",
       "      <td>0.289704</td>\n",
       "      <td>0.840646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + Under sampling</th>\n",
       "      <td>0.794593</td>\n",
       "      <td>0.286344</td>\n",
       "      <td>0.843338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision    Recall\n",
       "Dummy Classifier          0.909102   0.909091  1.000000\n",
       "Logistic regression (LR)  0.926866   0.727426  0.313594\n",
       "LR + class weights        0.798116   0.289704  0.840646\n",
       "LR + Under sampling       0.794593   0.286344  0.843338"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "##### UNDER SAMPLING\n",
    "## Add the undersampling step to our pipeline\n",
    "lr_clf = make_pipeline_with_sampler(\n",
    "    preprocessor_linear,\n",
    "    RandomUnderSampler(random_state=23),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")\n",
    "\n",
    "## Cross-validation\n",
    "lr_cv_result_s = cross_validate(lr_clf, df_res, y_res_clean, scoring = ['accuracy', 'precision', 'recall'])\n",
    "\n",
    "\n",
    "## Save scores\n",
    "index += [\"LR + Under sampling\"]\n",
    "scores[\"Accuracy\"].append(lr_cv_result_s[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(lr_cv_result_s[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(lr_cv_result_s[\"test_recall\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rg7pAfI4dWDP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <td>0.909102</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic regression (LR)</th>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.727426</td>\n",
       "      <td>0.313594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + class weights</th>\n",
       "      <td>0.798116</td>\n",
       "      <td>0.289704</td>\n",
       "      <td>0.840646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + Under sampling</th>\n",
       "      <td>0.794593</td>\n",
       "      <td>0.286344</td>\n",
       "      <td>0.843338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR + SMOTE</th>\n",
       "      <td>0.800685</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.830686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precision    Recall\n",
       "Dummy Classifier          0.909102   0.909091  1.000000\n",
       "Logistic regression (LR)  0.926866   0.727426  0.313594\n",
       "LR + class weights        0.798116   0.289704  0.840646\n",
       "LR + Under sampling       0.794593   0.286344  0.843338\n",
       "LR + SMOTE                0.800685   0.291100  0.830686"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### SMOTE\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "### Add SMOTE to the pipeline\n",
    "lr_clf = make_pipeline_with_sampler(\n",
    "    preprocessor_linear,\n",
    "    SMOTE(random_state=42),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")\n",
    "\n",
    "### Cross-validate\n",
    "lr_cv_result_smote = cross_validate(lr_clf, df_res, y_res_clean, scoring = ['accuracy', 'precision', 'recall'])\n",
    "\n",
    "\n",
    "### Store scores\n",
    "index += [\"LR + SMOTE\"]\n",
    "scores[\"Accuracy\"].append(lr_cv_result_smote[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(lr_cv_result_smote[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(lr_cv_result_smote[\"test_recall\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCowk0bkkMhZ"
   },
   "source": [
    "# YOUR TURN\n",
    "\n",
    "Your task is to replicate the workflow above, focusing on a random-forest classifier.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Start by building the pre-processing pipeline\n",
    "2. Build and evaluate:\n",
    "\n",
    "*   Baseline random forest-classifier\n",
    "*   with class weights = 'balanced'\n",
    "*   with under-sampling\n",
    "*   with over-sampling\n",
    "\n",
    "3. Assess and compare performance across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NkUt74-kt1I"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "num_pipe = SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    "cat_pipe = make_pipeline() ##### COMPLETE THIS STEP\n",
    "\n",
    "preprocessor_RF = make_column_transformer(\n",
    "\n",
    ") ### FILL OUT THE make column transformer function\n",
    "\n",
    "rf_pipeline = make_pipeline(\n",
    "    preprocessor_RF, RandomForestClassifier(random_state=23)\n",
    ")\n",
    "\n",
    "RF_SCORING = [\"accuracy\", \"precision\", \"recall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM4pBg00qKiY"
   },
   "source": [
    "### A. RANDOM FOREST BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NdobLANkwKe"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_result = cross_validate() ### TO COMPLETE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sTWfiuXlon5"
   },
   "outputs": [],
   "source": [
    "## Evaluate Performance\n",
    "index = [\"Random forest (RF)\"]\n",
    "scores = {'Accuracy':[],'Precision':[], 'Recall':[]}\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(cv_result[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(cv_result[\"test_recall\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kzCrGXPqjcD"
   },
   "source": [
    "### B. Balanced Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5896p5v0lVr6"
   },
   "outputs": [],
   "source": [
    "### RANDOM FOREST with class weights\n",
    "\n",
    "rf_pipeline.set_params() #### COMPLETE THIS STEP\n",
    "\n",
    "cv_result = cross_validate() #### COMPLETE THIS STEP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAD2No12lshZ"
   },
   "outputs": [],
   "source": [
    "#### Evaluate Performance\n",
    "index += [\"RF (Class Weights)\"]\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(cv_result[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(cv_result[\"test_recall\"].mean())\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGEfn9sqm06"
   },
   "source": [
    "### C. Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtxsQaTPmQuZ"
   },
   "outputs": [],
   "source": [
    "#### COMPLETE THIS STEP\n",
    "rf_pipeline = make_pipeline_with_sampler(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FFbEF3tm1DG"
   },
   "outputs": [],
   "source": [
    "index += [\"RF + Under sampling\"]\n",
    "cv_result = cross_validate(rf_pipeline, df_res, y_res_clean, scoring=RF_SCORING)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(cv_result[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(cv_result[\"test_recall\"].mean())\n",
    "\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iycaSivurV5b"
   },
   "source": [
    "### D. OVER SAMPLING (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R6iQVqWnLFg"
   },
   "outputs": [],
   "source": [
    "#### COMPLETE THIS\n",
    "rf_pipeline = make_pipeline_with_sampler(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkCFruFznRtu"
   },
   "outputs": [],
   "source": [
    "index += [\"RF + SMOTE\"]\n",
    "cv_result = cross_validate(rf_pipeline, df_res, y_res_clean, scoring=RF_SCORING)\n",
    "scores[\"Accuracy\"].append(cv_result[\"test_accuracy\"].mean())\n",
    "scores[\"Precision\"].append(cv_result[\"test_precision\"].mean())\n",
    "scores[\"Recall\"].append(cv_result[\"test_recall\"].mean())\n",
    "\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=index)\n",
    "df_scores"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhlD7D9oE/UxcKqNiPBlA3",
   "provenance": [
    {
     "file_id": "1P00AnBMay_D1H_jV8Jo98Ibv8v2BF_DS",
     "timestamp": 1713367398321
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
